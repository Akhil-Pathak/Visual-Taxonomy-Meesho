{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:37.804597Z",
     "iopub.status.busy": "2024-11-16T13:42:37.804057Z",
     "iopub.status.idle": "2024-11-16T13:42:37.809248Z",
     "shell.execute_reply": "2024-11-16T13:42:37.808363Z",
     "shell.execute_reply.started": "2024-11-16T13:42:37.804557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:37.811986Z",
     "iopub.status.busy": "2024-11-16T13:42:37.811157Z",
     "iopub.status.idle": "2024-11-16T13:42:37.819097Z",
     "shell.execute_reply": "2024-11-16T13:42:37.818058Z",
     "shell.execute_reply.started": "2024-11-16T13:42:37.811939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_category = 'Women Tops & Tunics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:37.830248Z",
     "iopub.status.busy": "2024-11-16T13:42:37.829792Z",
     "iopub.status.idle": "2024-11-16T13:42:37.834367Z",
     "shell.execute_reply": "2024-11-16T13:42:37.833383Z",
     "shell.execute_reply.started": "2024-11-16T13:42:37.830216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_eff_b6 = \"../../Models/eff_net_b6_fillna_eff_net_Women Tops Tunics.pth\"\n",
    "path_swin_v2 = \"../../Models/Tops_swin_v2.pth\"\n",
    "path_mobile_v3_large = \"../../Models/mobile_net_v3_large_fillna_eff_net_Women Tops_Tunics.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:37.858163Z",
     "iopub.status.busy": "2024-11-16T13:42:37.857863Z",
     "iopub.status.idle": "2024-11-16T13:42:38.004002Z",
     "shell.execute_reply": "2024-11-16T13:42:38.003047Z",
     "shell.execute_reply.started": "2024-11-16T13:42:37.858131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51375</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>black</td>\n",
       "      <td>regular</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51376</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>navy blue</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>high</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51377</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>red</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>knitted</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51378</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>stylised</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51379</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>boxy</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>tie-ups</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/051...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>70374</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>square neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>70375</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>yellow</td>\n",
       "      <td>regular</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19001</th>\n",
       "      <td>70376</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>maroon</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19002</th>\n",
       "      <td>70377</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>green</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>high</td>\n",
       "      <td>party</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>ruffles</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19003</th>\n",
       "      <td>70378</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>pink</td>\n",
       "      <td>boxy</td>\n",
       "      <td>crop</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19004 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len      attr_1   attr_2   attr_3  \\\n",
       "0      51375  Women Tops & Tunics   10       black  regular     crop   \n",
       "1      51376  Women Tops & Tunics   10   navy blue   fitted     crop   \n",
       "2      51377  Women Tops & Tunics   10         red  regular  regular   \n",
       "3      51378  Women Tops & Tunics   10     default   fitted     crop   \n",
       "4      51379  Women Tops & Tunics   10     default     boxy  regular   \n",
       "...      ...                  ...  ...         ...      ...      ...   \n",
       "18999  70374  Women Tops & Tunics   10  multicolor   fitted  regular   \n",
       "19000  70375  Women Tops & Tunics   10      yellow  regular     crop   \n",
       "19001  70376  Women Tops & Tunics   10      maroon   fitted     crop   \n",
       "19002  70377  Women Tops & Tunics   10       green  regular  regular   \n",
       "19003  70378  Women Tops & Tunics   10        pink     boxy     crop   \n",
       "\n",
       "            attr_4  attr_5   attr_6      attr_7         attr_8  \\\n",
       "0       round neck  casual  default     default  short sleeves   \n",
       "1             high  casual  default       solid  short sleeves   \n",
       "2       round neck  casual  printed  typography     sleeveless   \n",
       "3         stylised  casual    solid       solid  short sleeves   \n",
       "4       round neck  casual  printed  typography  short sleeves   \n",
       "...            ...     ...      ...         ...            ...   \n",
       "18999  square neck  casual  printed     default  short sleeves   \n",
       "19000   round neck  casual  default     default  short sleeves   \n",
       "19001   round neck  casual    solid       solid  short sleeves   \n",
       "19002         high   party    solid       solid  short sleeves   \n",
       "19003       v-neck  casual  printed  typography  short sleeves   \n",
       "\n",
       "                attr_9  attr_10  \\\n",
       "0      regular sleeves  knitted   \n",
       "1              default  knitted   \n",
       "2           sleeveless  knitted   \n",
       "3      regular sleeves  default   \n",
       "4              default  tie-ups   \n",
       "...                ...      ...   \n",
       "18999  regular sleeves  ruffles   \n",
       "19000  regular sleeves  knitted   \n",
       "19001  regular sleeves  knitted   \n",
       "19002          default  ruffles   \n",
       "19003  regular sleeves  default   \n",
       "\n",
       "                                              image_path  \n",
       "0      /kaggle/input/visual-taxonomy/train_images/051...  \n",
       "1      /kaggle/input/visual-taxonomy/train_images/051...  \n",
       "2      /kaggle/input/visual-taxonomy/train_images/051...  \n",
       "3      /kaggle/input/visual-taxonomy/train_images/051...  \n",
       "4      /kaggle/input/visual-taxonomy/train_images/051...  \n",
       "...                                                  ...  \n",
       "18999  /kaggle/input/visual-taxonomy/train_images/070...  \n",
       "19000  /kaggle/input/visual-taxonomy/train_images/070...  \n",
       "19001  /kaggle/input/visual-taxonomy/train_images/070...  \n",
       "19002  /kaggle/input/visual-taxonomy/train_images/070...  \n",
       "19003  /kaggle/input/visual-taxonomy/train_images/070...  \n",
       "\n",
       "[19004 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_Men_Tshirts = pd.read_csv('../../Preprocessor-FillNA/output/train_fillna_Women Tops Tunics_effnet_b5_4epochs.csv')\n",
    "train_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:38.006350Z",
     "iopub.status.busy": "2024-11-16T13:42:38.006019Z",
     "iopub.status.idle": "2024-11-16T13:42:38.016615Z",
     "shell.execute_reply": "2024-11-16T13:42:38.015607Z",
     "shell.execute_reply.started": "2024-11-16T13:42:38.006308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5', 'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10']\n"
     ]
    }
   ],
   "source": [
    "attr_columns = train_df_Men_Tshirts.filter(like='attr_').columns.to_list() # Adjust if more attributes exist\n",
    "print(attr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:38.018237Z",
     "iopub.status.busy": "2024-11-16T13:42:38.017833Z",
     "iopub.status.idle": "2024-11-16T13:42:39.080859Z",
     "shell.execute_reply": "2024-11-16T13:42:39.080028Z",
     "shell.execute_reply.started": "2024-11-16T13:42:38.018195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder for each attribute column\n",
    "label_encoders = {}\n",
    "for column in attr_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df_Men_Tshirts[column] = le.fit_transform(train_df_Men_Tshirts[column])\n",
    "    label_encoders[column] = le  # Store the encoder for inverse transformation later if needed\n",
    "\n",
    "# Check the updated DataFrame\n",
    "# train_df_Men_Tshirts = train_df_Men_Tshirts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:39.083421Z",
     "iopub.status.busy": "2024-11-16T13:42:39.082981Z",
     "iopub.status.idle": "2024-11-16T13:42:39.174123Z",
     "shell.execute_reply": "2024-11-16T13:42:39.173297Z",
     "shell.execute_reply.started": "2024-11-16T13:42:39.083385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df1, val_df1 = train_test_split(train_df_Men_Tshirts, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:39.175744Z",
     "iopub.status.busy": "2024-11-16T13:42:39.175389Z",
     "iopub.status.idle": "2024-11-16T13:42:44.027353Z",
     "shell.execute_reply": "2024-11-16T13:42:44.026571Z",
     "shell.execute_reply.started": "2024-11-16T13:42:39.175707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test  # Flag to indicate if it's test set without labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + self.dataframe.iloc[idx]['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:  # For test set, just return the image without labels\n",
    "            return image\n",
    "        \n",
    "        # For train/validation set, return image and labels\n",
    "        labels = self.dataframe.iloc[idx][attr_columns].values\n",
    "        labels = labels.astype(np.int64)  # Ensure labels are integers\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return image, labels\n",
    "    \n",
    "    \n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Apply Color Jitter\n",
    "    transforms.RandomHorizontalFlip(),  # Apply Horizontal Flip with 50% probability\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "    \n",
    "train_dataset = CustomDataset(dataframe=train_df1, img_dir='', transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=val_df1, img_dir='', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:44.028850Z",
     "iopub.status.busy": "2024-11-16T13:42:44.028414Z",
     "iopub.status.idle": "2024-11-16T13:42:44.032982Z",
     "shell.execute_reply": "2024-11-16T13:42:44.032048Z",
     "shell.execute_reply.started": "2024-11-16T13:42:44.028816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:44.034480Z",
     "iopub.status.busy": "2024-11-16T13:42:44.034156Z",
     "iopub.status.idle": "2024-11-16T13:42:48.478035Z",
     "shell.execute_reply": "2024-11-16T13:42:48.476903Z",
     "shell.execute_reply.started": "2024-11-16T13:42:44.034418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B6_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B6_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b6_lukemelas-24a108a5.pth\n",
      "100%|██████████| 165M/165M [00:02<00:00, 60.8MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "class MultiOutputModel1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiOutputModel1, self).__init__()\n",
    "        # Use MobileNetV2 as the base model\n",
    "        self.base_model = models.efficientnet_b6(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()  # Remove original classification layer\n",
    "        \n",
    "        # Add an adaptive pooling layer to make sure output is flat\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))  # Convert 2D output to 1D\n",
    "        \n",
    "        # Dynamically create a fully connected layer for each attribute\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        for attr, n_classes in num_classes.items():\n",
    "            self.output_layers[attr] = nn.Linear(2304, n_classes)  # Adjust input to 1280 for MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)  # Extract features\n",
    "        x = self.pooling(x)  # Adaptive pool to (1, 1) shape\n",
    "        x = torch.flatten(x, 1)  # Flatten the output to (batch_size, 1280)\n",
    "        \n",
    "        outputs = {}\n",
    "        # Dynamically compute output for each attribute\n",
    "        for attr, layer in self.output_layers.items():\n",
    "            outputs[attr] = layer(x)\n",
    "        \n",
    "        return list(outputs.values())\n",
    "\n",
    "# Example usage\n",
    "num_classes = {}\n",
    "for key in attr_columns:\n",
    "    num_classes[key] = train_df_Men_Tshirts[key].nunique()\n",
    "\n",
    "model_eff_b6 = MultiOutputModel1(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff_b6.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:48.480334Z",
     "iopub.status.busy": "2024-11-16T13:42:48.479452Z",
     "iopub.status.idle": "2024-11-16T13:42:52.722550Z",
     "shell.execute_reply": "2024-11-16T13:42:52.721709Z",
     "shell.execute_reply.started": "2024-11-16T13:42:48.480288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/swin_v2_b-781e5279.pth\" to /root/.cache/torch/hub/checkpoints/swin_v2_b-781e5279.pth\n",
      "100%|██████████| 336M/336M [00:01<00:00, 185MB/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "class MultiOutputModel2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiOutputModel2, self).__init__()\n",
    "        # Use MobileNetV2 as the base model\n",
    "        # Load a pretrained Swin V2 model\n",
    "        self.base_model = models.swin_v2_b(weights=\"IMAGENET1K_V1\")\n",
    "        \n",
    "        # Remove the original classification head\n",
    "        in_features = self.base_model.head.in_features  # Get the input features for the head\n",
    "        self.base_model.head = nn.Identity()  # Replace with identity to extract embeddings\n",
    "        \n",
    "        # Define output layers for each attribute dynamically\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        for attr, n_classes in num_classes.items():\n",
    "            self.output_layers[attr] = nn.Linear(in_features, n_classes)  # Use `in_features` for each linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the Swin model to get embeddings\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Compute output for each attribute\n",
    "        outputs = {attr: layer(x) for attr, layer in self.output_layers.items()}\n",
    "        \n",
    "        return list(outputs.values())\n",
    "\n",
    "# Example usage\n",
    "num_classes = {}\n",
    "for key in attr_columns:\n",
    "    num_classes[key] = train_df_Men_Tshirts[key].nunique()\n",
    "\n",
    "model_swin_v2 = MultiOutputModel2(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_swin_v2.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:52.724167Z",
     "iopub.status.busy": "2024-11-16T13:42:52.723801Z",
     "iopub.status.idle": "2024-11-16T13:42:53.119837Z",
     "shell.execute_reply": "2024-11-16T13:42:53.118841Z",
     "shell.execute_reply.started": "2024-11-16T13:42:52.724125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 124MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "class MultiOutputModel3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiOutputModel3, self).__init__()\n",
    "        # Use MobileNetV2 as the base model\n",
    "        self.base_model = models.mobilenet_v3_large(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()  # Remove original classification layer\n",
    "        \n",
    "        # Add an adaptive pooling layer to make sure output is flat\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))  # Convert 2D output to 1D\n",
    "        \n",
    "        # Dynamically create a fully connected layer for each attribute\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        for attr, n_classes in num_classes.items():\n",
    "            self.output_layers[attr] = nn.Linear(960, n_classes)  # Adjust input to 1280 for MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)  # Extract features\n",
    "        x = self.pooling(x)  # Adaptive pool to (1, 1) shape\n",
    "        x = torch.flatten(x, 1)  # Flatten the output to (batch_size, 1280)\n",
    "        \n",
    "        outputs = {}\n",
    "        # Dynamically compute output for each attribute\n",
    "        for attr, layer in self.output_layers.items():\n",
    "            outputs[attr] = layer(x)\n",
    "        \n",
    "        return list(outputs.values())\n",
    "\n",
    "# Example usage\n",
    "num_classes = {}\n",
    "for key in attr_columns:\n",
    "    num_classes[key] = train_df_Men_Tshirts[key].nunique()\n",
    "\n",
    "model_mobile_net_v3_large = MultiOutputModel3(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mobile_net_v3_large.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:53.123597Z",
     "iopub.status.busy": "2024-11-16T13:42:53.123255Z",
     "iopub.status.idle": "2024-11-16T13:42:53.589233Z",
     "shell.execute_reply": "2024-11-16T13:42:53.588149Z",
     "shell.execute_reply.started": "2024-11-16T13:42:53.123557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_eff_b6 = model_eff_b6.to(device)\n",
    "model_swin_v2 =  model_swin_v2.to(device)\n",
    "model_mobile_net_v3_large = model_mobile_net_v3_large.to(device)\n",
    "# Training loop\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, save_path=f\"eff_net_b6_fillna_eff_net_{model_category}.pth\"):\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer = optimizer , step_size=5, gamma=0.5)\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move tensors to the correct device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = sum([criterion(output, label) for output, label in zip(outputs, labels.T)])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader)}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)  # Move tensors to the correct device\n",
    "                outputs = model(images)\n",
    "                loss = sum([criterion(output, label) for output, label in zip(outputs, labels.T)])\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Epoch {epoch+1}, Val Loss: {val_loss/len(val_loader)}')\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved with Val Loss: {best_val_loss:.4f} at Epoch {epoch+1}\")\n",
    "\n",
    "# Run training\n",
    "# train(model, train_loader, val_loader, criterion, optimizer, num_epochs=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:53.591120Z",
     "iopub.status.busy": "2024-11-16T13:42:53.590768Z",
     "iopub.status.idle": "2024-11-16T13:42:55.303188Z",
     "shell.execute_reply": "2024-11-16T13:42:55.302215Z",
     "shell.execute_reply.started": "2024-11-16T13:42:53.591087Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/563325272.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_eff_b6.load_state_dict(torch.load(f\"{path_eff_b6}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_eff_b6.load_state_dict(torch.load(f\"{path_eff_b6}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:55.305066Z",
     "iopub.status.busy": "2024-11-16T13:42:55.304653Z",
     "iopub.status.idle": "2024-11-16T13:42:57.259090Z",
     "shell.execute_reply": "2024-11-16T13:42:57.258137Z",
     "shell.execute_reply.started": "2024-11-16T13:42:55.305020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3335458680.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_swin_v2.load_state_dict(torch.load(f\"{path_swin_v2}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_swin_v2.load_state_dict(torch.load(f\"{path_swin_v2}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.261122Z",
     "iopub.status.busy": "2024-11-16T13:42:57.260399Z",
     "iopub.status.idle": "2024-11-16T13:42:57.444923Z",
     "shell.execute_reply": "2024-11-16T13:42:57.444037Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.261073Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/2865226030.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_mobile_net_v3_large.load_state_dict(torch.load(f\"{path_mobile_v3_large}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_mobile_net_v3_large.load_state_dict(torch.load(f\"{path_mobile_v3_large}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.446196Z",
     "iopub.status.busy": "2024-11-16T13:42:57.445922Z",
     "iopub.status.idle": "2024-11-16T13:42:57.474192Z",
     "shell.execute_reply": "2024-11-16T13:42:57.473306Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.446166Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputModel1(\n",
       "  (base_model): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(56, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n",
       "              (1): BatchNorm2d(56, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(56, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(14, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0044444444444444444, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.008888888888888889, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.013333333333333336, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017777777777777778, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.022222222222222223, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.026666666666666672, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.031111111111111114, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.035555555555555556, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.044444444444444446, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04888888888888889, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.053333333333333344, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05777777777777778, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06222222222222223, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07111111111111111, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07555555555555557, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08444444444444445, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08888888888888889, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09777777777777778, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10222222222222223, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10666666666666669, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1111111111111111, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11555555555555556, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12444444444444445, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12888888888888891, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13777777777777778, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14222222222222222, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15111111111111114, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15555555555555556, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16444444444444445, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1688888888888889, mode=row)\n",
       "        )\n",
       "        (8): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
       "        )\n",
       "        (9): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17777777777777778, mode=row)\n",
       "        )\n",
       "        (10): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18222222222222226, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 3456, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3456, bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3456, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(144, 3456, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1911111111111111, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 3456, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3456, bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3456, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(144, 3456, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19555555555555557, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layers): ModuleDict(\n",
       "    (attr_1): Linear(in_features=2304, out_features=12, bias=True)\n",
       "    (attr_2): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_3): Linear(in_features=2304, out_features=2, bias=True)\n",
       "    (attr_4): Linear(in_features=2304, out_features=7, bias=True)\n",
       "    (attr_5): Linear(in_features=2304, out_features=2, bias=True)\n",
       "    (attr_6): Linear(in_features=2304, out_features=3, bias=True)\n",
       "    (attr_7): Linear(in_features=2304, out_features=6, bias=True)\n",
       "    (attr_8): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_9): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_10): Linear(in_features=2304, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eff_b6.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.475700Z",
     "iopub.status.busy": "2024-11-16T13:42:57.475272Z",
     "iopub.status.idle": "2024-11-16T13:42:57.490738Z",
     "shell.execute_reply": "2024-11-16T13:42:57.489687Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.475655Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputModel2(\n",
       "  (base_model): SwinTransformer(\n",
       "    (features): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=4, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=32, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (permute): Permute()\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (output_layers): ModuleDict(\n",
       "    (attr_1): Linear(in_features=1024, out_features=12, bias=True)\n",
       "    (attr_2): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (attr_3): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (attr_4): Linear(in_features=1024, out_features=7, bias=True)\n",
       "    (attr_5): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    (attr_6): Linear(in_features=1024, out_features=3, bias=True)\n",
       "    (attr_7): Linear(in_features=1024, out_features=6, bias=True)\n",
       "    (attr_8): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (attr_9): Linear(in_features=1024, out_features=4, bias=True)\n",
       "    (attr_10): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_swin_v2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.492341Z",
     "iopub.status.busy": "2024-11-16T13:42:57.492010Z",
     "iopub.status.idle": "2024-11-16T13:42:57.506059Z",
     "shell.execute_reply": "2024-11-16T13:42:57.504923Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.492307Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputModel3(\n",
       "  (base_model): MobileNetV3(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layers): ModuleDict(\n",
       "    (attr_1): Linear(in_features=960, out_features=12, bias=True)\n",
       "    (attr_2): Linear(in_features=960, out_features=4, bias=True)\n",
       "    (attr_3): Linear(in_features=960, out_features=2, bias=True)\n",
       "    (attr_4): Linear(in_features=960, out_features=7, bias=True)\n",
       "    (attr_5): Linear(in_features=960, out_features=2, bias=True)\n",
       "    (attr_6): Linear(in_features=960, out_features=3, bias=True)\n",
       "    (attr_7): Linear(in_features=960, out_features=6, bias=True)\n",
       "    (attr_8): Linear(in_features=960, out_features=4, bias=True)\n",
       "    (attr_9): Linear(in_features=960, out_features=4, bias=True)\n",
       "    (attr_10): Linear(in_features=960, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mobile_net_v3_large.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.508221Z",
     "iopub.status.busy": "2024-11-16T13:42:57.507194Z",
     "iopub.status.idle": "2024-11-16T13:42:57.538439Z",
     "shell.execute_reply": "2024-11-16T13:42:57.537486Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.508185Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>30484</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>30485</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>30486</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>30487</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30488</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category\n",
       "0          0          Men Tshirts\n",
       "1          1          Men Tshirts\n",
       "2          2          Men Tshirts\n",
       "3          3          Men Tshirts\n",
       "4          4          Men Tshirts\n",
       "...      ...                  ...\n",
       "30200  30484  Women Tops & Tunics\n",
       "30201  30485  Women Tops & Tunics\n",
       "30202  30486  Women Tops & Tunics\n",
       "30203  30487  Women Tops & Tunics\n",
       "30204  30488  Women Tops & Tunics\n",
       "\n",
       "[30205 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../Dataset/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.540028Z",
     "iopub.status.busy": "2024-11-16T13:42:57.539706Z",
     "iopub.status.idle": "2024-11-16T13:42:57.640454Z",
     "shell.execute_reply": "2024-11-16T13:42:57.639542Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.539994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/2828864867.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts['len'] = 10\n",
      "/tmp/ipykernel_30/2828864867.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts['image_path'] = test_df_Men_Tshirts.apply(format_image_path_test, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>23564</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>23565</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>23566</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>23567</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>23568</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>30484</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>30485</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>30486</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>30487</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30488</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6925 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len  \\\n",
       "23280  23564  Women Tops & Tunics   10   \n",
       "23281  23565  Women Tops & Tunics   10   \n",
       "23282  23566  Women Tops & Tunics   10   \n",
       "23283  23567  Women Tops & Tunics   10   \n",
       "23284  23568  Women Tops & Tunics   10   \n",
       "...      ...                  ...  ...   \n",
       "30200  30484  Women Tops & Tunics   10   \n",
       "30201  30485  Women Tops & Tunics   10   \n",
       "30202  30486  Women Tops & Tunics   10   \n",
       "30203  30487  Women Tops & Tunics   10   \n",
       "30204  30488  Women Tops & Tunics   10   \n",
       "\n",
       "                                              image_path  \n",
       "23280  /kaggle/input/visual-taxonomy/test_images/0235...  \n",
       "23281  /kaggle/input/visual-taxonomy/test_images/0235...  \n",
       "23282  /kaggle/input/visual-taxonomy/test_images/0235...  \n",
       "23283  /kaggle/input/visual-taxonomy/test_images/0235...  \n",
       "23284  /kaggle/input/visual-taxonomy/test_images/0235...  \n",
       "...                                                  ...  \n",
       "30200  /kaggle/input/visual-taxonomy/test_images/0304...  \n",
       "30201  /kaggle/input/visual-taxonomy/test_images/0304...  \n",
       "30202  /kaggle/input/visual-taxonomy/test_images/0304...  \n",
       "30203  /kaggle/input/visual-taxonomy/test_images/0304...  \n",
       "30204  /kaggle/input/visual-taxonomy/test_images/0304...  \n",
       "\n",
       "[6925 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_Men_Tshirts = test_df[test_df['Category'] == model_category]\n",
    "test_df_Men_Tshirts['len'] = 10\n",
    "\n",
    "def format_image_path_test(row):\n",
    "    return f\"../../Dataset/test_images/{str(row['id']).zfill(6)}.jpg\"\n",
    "\n",
    "test_df_Men_Tshirts['image_path'] = test_df_Men_Tshirts.apply(format_image_path_test, axis=1)\n",
    "test_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.641973Z",
     "iopub.status.busy": "2024-11-16T13:42:57.641677Z",
     "iopub.status.idle": "2024-11-16T13:42:57.646140Z",
     "shell.execute_reply": "2024-11-16T13:42:57.645158Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.641941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_df_Men_Tshirts = test_df_Men_Tshirts.sample(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.648446Z",
     "iopub.status.busy": "2024-11-16T13:42:57.647707Z",
     "iopub.status.idle": "2024-11-16T13:42:57.655449Z",
     "shell.execute_reply": "2024-11-16T13:42:57.654550Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.648391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test dataset without labels\n",
    "torch.manual_seed(42)\n",
    "test_dataset = CustomDataset(dataframe=test_df_Men_Tshirts, img_dir='', transform=transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.657214Z",
     "iopub.status.busy": "2024-11-16T13:42:57.656855Z",
     "iopub.status.idle": "2024-11-16T13:42:57.664499Z",
     "shell.execute_reply": "2024-11-16T13:42:57.663583Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.657177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:42:57.666123Z",
     "iopub.status.busy": "2024-11-16T13:42:57.665758Z",
     "iopub.status.idle": "2024-11-16T13:47:23.639783Z",
     "shell.execute_reply": "2024-11-16T13:47:23.638692Z",
     "shell.execute_reply.started": "2024-11-16T13:42:57.666079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [04:25<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  2  0 ...  2  3  2]\n",
      " [11  0  0 ...  1  2  1]\n",
      " [ 0  2  1 ...  0  2  0]\n",
      " ...\n",
      " [ 2  3  1 ...  1  0  2]\n",
      " [ 5  3  1 ...  0  2  3]\n",
      " [ 8  2  0 ...  2  0  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Use console version of tqdm\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader):  # This will display in the console\n",
    "        images = images.cuda() if torch.cuda.is_available() else images\n",
    "\n",
    "        # Forward pass through both models\n",
    "        torch.manual_seed(42)\n",
    "        outputs1 = model_eff_b6(images)\n",
    "        outputs2 = model_swin_v2(images)\n",
    "        outputs3 = model_mobile_net_v3_large(images)\n",
    "#         outputs3 = model_eff_b5(images)\n",
    "\n",
    "        # Initialize a list to hold blended predictions for the batch\n",
    "        batch_preds = []\n",
    "\n",
    "        # Loop through the outputs and blend predictions for each attribute\n",
    "        for out1, out2 ,out3 in zip(outputs1, outputs2,outputs3):\n",
    "            # Blend logits by averaging\n",
    "            torch.manual_seed(42)\n",
    "            blended_output = (out1 + out2 + out3)/3\n",
    "            # Get the predicted classes from the blended output\n",
    "            _, pred = torch.max(blended_output, 1)\n",
    "            batch_preds.append(pred.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "\n",
    "        # Stack predictions along a new dimension and add to predictions list\n",
    "        predictions.append(np.stack(batch_preds, axis=1))  # Shape: (batch_size, num_attributes)\n",
    "\n",
    "# Combine all predictions into a single array\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Display final predictions\n",
    "print(predictions)  # This will be an array with shape (num_samples, num_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.641263Z",
     "iopub.status.busy": "2024-11-16T13:47:23.640962Z",
     "iopub.status.idle": "2024-11-16T13:47:23.666439Z",
     "shell.execute_reply": "2024-11-16T13:47:23.665216Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.641231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr_columns] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>23564</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>23565</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>23566</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>23567</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>23568</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len  \\\n",
       "23280  23564  Women Tops & Tunics   10   \n",
       "23281  23565  Women Tops & Tunics   10   \n",
       "23282  23566  Women Tops & Tunics   10   \n",
       "23283  23567  Women Tops & Tunics   10   \n",
       "23284  23568  Women Tops & Tunics   10   \n",
       "\n",
       "                                              image_path  attr_1  attr_2  \\\n",
       "23280  /kaggle/input/visual-taxonomy/test_images/0235...       6       2   \n",
       "23281  /kaggle/input/visual-taxonomy/test_images/0235...      11       0   \n",
       "23282  /kaggle/input/visual-taxonomy/test_images/0235...       0       2   \n",
       "23283  /kaggle/input/visual-taxonomy/test_images/0235...       8       3   \n",
       "23284  /kaggle/input/visual-taxonomy/test_images/0235...       0       2   \n",
       "\n",
       "       attr_3  attr_4  attr_5  attr_6  attr_7  attr_8  attr_9  attr_10  \n",
       "23280       0       1       0       0       0       2       3        2  \n",
       "23281       0       2       0       1       2       1       2        1  \n",
       "23282       1       2       0       2       4       0       2        0  \n",
       "23283       1       6       0       2       4       1       0        2  \n",
       "23284       1       2       0       0       4       1       2        2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming predictions is a numpy array of shape (N, 5)\n",
    "# Add new columns attr_1 to attr_10 to test_df\n",
    "for i in range(1, 11):\n",
    "    test_df_Men_Tshirts[f'attr_{i}'] = np.nan \n",
    "\n",
    "# Assign predictions to attr_1 to attr_5\n",
    "test_df_Men_Tshirts[attr_columns] = predictions\n",
    "\n",
    "# Optionally save the updated test_df to CSV\n",
    "# test_df.to_csv('test_predictions_with_attrs.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "test_df_Men_Tshirts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.668225Z",
     "iopub.status.busy": "2024-11-16T13:47:23.667931Z",
     "iopub.status.idle": "2024-11-16T13:47:23.700470Z",
     "shell.execute_reply": "2024-11-16T13:47:23.699526Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.668194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>23564</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>navy blue</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>high</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>23565</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>yellow</td>\n",
       "      <td>boxy</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>graphic</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>23566</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>black</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>long sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>applique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>23567</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>pink</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>23568</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0235...</td>\n",
       "      <td>black</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>30484</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "      <td>green</td>\n",
       "      <td>boxy</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>tie-ups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>30485</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "      <td>default</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>puff sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>30486</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "      <td>default</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>30487</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>long sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>ruffles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30488</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n",
       "      <td>pink</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>default</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6925 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len  \\\n",
       "23280  23564  Women Tops & Tunics   10   \n",
       "23281  23565  Women Tops & Tunics   10   \n",
       "23282  23566  Women Tops & Tunics   10   \n",
       "23283  23567  Women Tops & Tunics   10   \n",
       "23284  23568  Women Tops & Tunics   10   \n",
       "...      ...                  ...  ...   \n",
       "30200  30484  Women Tops & Tunics   10   \n",
       "30201  30485  Women Tops & Tunics   10   \n",
       "30202  30486  Women Tops & Tunics   10   \n",
       "30203  30487  Women Tops & Tunics   10   \n",
       "30204  30488  Women Tops & Tunics   10   \n",
       "\n",
       "                                              image_path      attr_1   attr_2  \\\n",
       "23280  /kaggle/input/visual-taxonomy/test_images/0235...   navy blue   fitted   \n",
       "23281  /kaggle/input/visual-taxonomy/test_images/0235...      yellow     boxy   \n",
       "23282  /kaggle/input/visual-taxonomy/test_images/0235...       black   fitted   \n",
       "23283  /kaggle/input/visual-taxonomy/test_images/0235...        pink  regular   \n",
       "23284  /kaggle/input/visual-taxonomy/test_images/0235...       black   fitted   \n",
       "...                                                  ...         ...      ...   \n",
       "30200  /kaggle/input/visual-taxonomy/test_images/0304...       green     boxy   \n",
       "30201  /kaggle/input/visual-taxonomy/test_images/0304...     default  regular   \n",
       "30202  /kaggle/input/visual-taxonomy/test_images/0304...     default  regular   \n",
       "30203  /kaggle/input/visual-taxonomy/test_images/0304...  multicolor  regular   \n",
       "30204  /kaggle/input/visual-taxonomy/test_images/0304...        pink   fitted   \n",
       "\n",
       "        attr_3      attr_4  attr_5   attr_6      attr_7         attr_8  \\\n",
       "23280     crop        high  casual  default     default     sleeveless   \n",
       "23281     crop  round neck  casual  printed     graphic  short sleeves   \n",
       "23282  regular  round neck  casual    solid       solid   long sleeves   \n",
       "23283  regular      v-neck  casual    solid       solid  short sleeves   \n",
       "23284  regular  round neck  casual  default       solid  short sleeves   \n",
       "...        ...         ...     ...      ...         ...            ...   \n",
       "30200     crop  round neck  casual  printed  typography  short sleeves   \n",
       "30201  regular  round neck  casual    solid       solid  short sleeves   \n",
       "30202  regular      v-neck  casual    solid       solid  short sleeves   \n",
       "30203  regular  round neck  casual  default     default   long sleeves   \n",
       "30204     crop     default  casual    solid       solid     sleeveless   \n",
       "\n",
       "                attr_9   attr_10  \n",
       "23280       sleeveless   knitted  \n",
       "23281  regular sleeves   default  \n",
       "23282  regular sleeves  applique  \n",
       "23283          default   knitted  \n",
       "23284  regular sleeves   knitted  \n",
       "...                ...       ...  \n",
       "30200  regular sleeves   tie-ups  \n",
       "30201     puff sleeves   knitted  \n",
       "30202          default   knitted  \n",
       "30203  regular sleeves   ruffles  \n",
       "30204          default   knitted  \n",
       "\n",
       "[6925 rows x 14 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse transform predictions for each attribute using the stored label encoders\n",
    "for attr in attr_columns:\n",
    "    # Inverse transform using the corresponding label encoder\n",
    "    test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
    "\n",
    "# Check the updated DataFrame¯ with original attribute names instead of encoded numbers\n",
    "test_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.702092Z",
     "iopub.status.busy": "2024-11-16T13:47:23.701763Z",
     "iopub.status.idle": "2024-11-16T13:47:23.721766Z",
     "shell.execute_reply": "2024-11-16T13:47:23.720768Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.702056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for attr_1:\n",
      "\n",
      "attr_1\n",
      "black         903\n",
      "white         834\n",
      "pink          766\n",
      "default       725\n",
      "blue          627\n",
      "yellow        614\n",
      "red           599\n",
      "maroon        569\n",
      "green         502\n",
      "navy blue     291\n",
      "peach         264\n",
      "multicolor    231\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_2:\n",
      "\n",
      "attr_2\n",
      "fitted     2952\n",
      "regular    2527\n",
      "boxy        778\n",
      "default     668\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_3:\n",
      "\n",
      "attr_3\n",
      "regular    4407\n",
      "crop       2518\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_4:\n",
      "\n",
      "attr_4\n",
      "round neck         2847\n",
      "square neck         886\n",
      "high                739\n",
      "sweetheart neck     701\n",
      "default             684\n",
      "v-neck              660\n",
      "stylised            408\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_5:\n",
      "\n",
      "attr_5\n",
      "casual    6738\n",
      "party      187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_6:\n",
      "\n",
      "attr_6\n",
      "solid      4307\n",
      "printed    2030\n",
      "default     588\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_7:\n",
      "\n",
      "attr_7\n",
      "solid         4362\n",
      "default        716\n",
      "typography     707\n",
      "floral         524\n",
      "quirky         333\n",
      "graphic        283\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_8:\n",
      "\n",
      "attr_8\n",
      "short sleeves            4091\n",
      "long sleeves             1269\n",
      "three-quarter sleeves     909\n",
      "sleeveless                656\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_9:\n",
      "\n",
      "attr_9\n",
      "regular sleeves    3564\n",
      "puff sleeves       1938\n",
      "default             905\n",
      "sleeveless          518\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_10:\n",
      "\n",
      "attr_10\n",
      "knitted          3334\n",
      "default          1265\n",
      "ruffles           822\n",
      "tie-ups           557\n",
      "waist tie-ups     536\n",
      "applique          411\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get value counts for each specified column\n",
    "columns_of_interest = attr_columns\n",
    "\n",
    "for column in columns_of_interest:\n",
    "    print(f\"Value counts for {column}:\\n\")\n",
    "    print(test_df_Men_Tshirts[column].value_counts(dropna=False))  # Including NaN values\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.723438Z",
     "iopub.status.busy": "2024-11-16T13:47:23.723059Z",
     "iopub.status.idle": "2024-11-16T13:47:23.750826Z",
     "shell.execute_reply": "2024-11-16T13:47:23.749572Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.723399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47001</td>\n",
       "      <td>Women Tshirts</td>\n",
       "      <td>8</td>\n",
       "      <td>maroon</td>\n",
       "      <td>regular</td>\n",
       "      <td>crop</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>nu</td>\n",
       "      <td>nu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16431</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree\\n</td>\n",
       "      <td>temple border</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55700</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>white</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15698</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree\\n</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>white</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design\\n</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>floral</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30330</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>9</td>\n",
       "      <td>yellow</td>\n",
       "      <td>a-line</td>\n",
       "      <td>knee length\\n</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "      <td>nu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             Category  len           attr_1         attr_2  \\\n",
       "0  47001        Women Tshirts    8           maroon        regular   \n",
       "1  16431               Sarees   10  same as saree\\n  temple border   \n",
       "2  55700  Women Tops & Tunics   10            white         fitted   \n",
       "3  15698               Sarees   10  same as saree\\n           zari   \n",
       "4  30330               Kurtis    9           yellow         a-line   \n",
       "\n",
       "          attr_3      attr_4      attr_5         attr_6           attr_7  \\\n",
       "0           crop     printed  typography  short sleeves  regular sleeves   \n",
       "1   small border       cream       party       jacquard     woven design   \n",
       "2        regular  round neck      casual          solid            solid   \n",
       "3   small border       white       party       jacquard   woven design\\n   \n",
       "4  knee length\\n       daily         net        default            solid   \n",
       "\n",
       "                  attr_8           attr_9  attr_10  \n",
       "0                default               nu       nu  \n",
       "1             zari woven     ethnic motif       no  \n",
       "2          short sleeves  regular sleeves  knitted  \n",
       "3             zari woven           floral       no  \n",
       "4  three-quarter sleeves          regular       nu  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../../Dataset/sample_submission.csv')\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.752410Z",
     "iopub.status.busy": "2024-11-16T13:47:23.752073Z",
     "iopub.status.idle": "2024-11-16T13:47:23.769069Z",
     "shell.execute_reply": "2024-11-16T13:47:23.768164Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.752375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_Men_Tshirts = test_df_Men_Tshirts.fillna('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:47:23.774976Z",
     "iopub.status.busy": "2024-11-16T13:47:23.774668Z",
     "iopub.status.idle": "2024-11-16T13:47:23.857037Z",
     "shell.execute_reply": "2024-11-16T13:47:23.856028Z",
     "shell.execute_reply.started": "2024-11-16T13:47:23.774943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23280</th>\n",
       "      <td>23564</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>navy blue</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>high</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23281</th>\n",
       "      <td>23565</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>yellow</td>\n",
       "      <td>boxy</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>graphic</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>23566</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>black</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>long sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>applique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23283</th>\n",
       "      <td>23567</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>pink</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23284</th>\n",
       "      <td>23568</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>black</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>30484</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>green</td>\n",
       "      <td>boxy</td>\n",
       "      <td>crop</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>tie-ups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>30485</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>puff sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>30486</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>30487</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>regular</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>long sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>ruffles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30488</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>pink</td>\n",
       "      <td>fitted</td>\n",
       "      <td>crop</td>\n",
       "      <td>default</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>sleeveless</td>\n",
       "      <td>default</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6925 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len      attr_1   attr_2   attr_3  \\\n",
       "23280  23564  Women Tops & Tunics   10   navy blue   fitted     crop   \n",
       "23281  23565  Women Tops & Tunics   10      yellow     boxy     crop   \n",
       "23282  23566  Women Tops & Tunics   10       black   fitted  regular   \n",
       "23283  23567  Women Tops & Tunics   10        pink  regular  regular   \n",
       "23284  23568  Women Tops & Tunics   10       black   fitted  regular   \n",
       "...      ...                  ...  ...         ...      ...      ...   \n",
       "30200  30484  Women Tops & Tunics   10       green     boxy     crop   \n",
       "30201  30485  Women Tops & Tunics   10     default  regular  regular   \n",
       "30202  30486  Women Tops & Tunics   10     default  regular  regular   \n",
       "30203  30487  Women Tops & Tunics   10  multicolor  regular  regular   \n",
       "30204  30488  Women Tops & Tunics   10        pink   fitted     crop   \n",
       "\n",
       "           attr_4  attr_5   attr_6      attr_7         attr_8  \\\n",
       "23280        high  casual  default     default     sleeveless   \n",
       "23281  round neck  casual  printed     graphic  short sleeves   \n",
       "23282  round neck  casual    solid       solid   long sleeves   \n",
       "23283      v-neck  casual    solid       solid  short sleeves   \n",
       "23284  round neck  casual  default       solid  short sleeves   \n",
       "...           ...     ...      ...         ...            ...   \n",
       "30200  round neck  casual  printed  typography  short sleeves   \n",
       "30201  round neck  casual    solid       solid  short sleeves   \n",
       "30202      v-neck  casual    solid       solid  short sleeves   \n",
       "30203  round neck  casual  default     default   long sleeves   \n",
       "30204     default  casual    solid       solid     sleeveless   \n",
       "\n",
       "                attr_9   attr_10  \n",
       "23280       sleeveless   knitted  \n",
       "23281  regular sleeves   default  \n",
       "23282  regular sleeves  applique  \n",
       "23283          default   knitted  \n",
       "23284  regular sleeves   knitted  \n",
       "...                ...       ...  \n",
       "30200  regular sleeves   tie-ups  \n",
       "30201     puff sleeves   knitted  \n",
       "30202          default   knitted  \n",
       "30203  regular sleeves   ruffles  \n",
       "30204          default   knitted  \n",
       "\n",
       "[6925 rows x 13 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_Men_Tshirts = test_df_Men_Tshirts.drop('image_path', axis = 1)\n",
    "# sub_df_Men_Tshirts.replace(\"unknown\", np.nan, inplace=True)\n",
    "sub_df_Men_Tshirts.to_csv(f\"output/sub_df_{model_category}_effnet_0.33_b6_0.33_swin_v2_0.33_mobile_net_v3_large_blending.csv\", index = False)\n",
    "sub_df_Men_Tshirts.to_csv(f\"sub_df_{model_category}_effnet_0.33_b6_0.33_swin_v2_0.33_mobile_net_v3_large_blending.csv\", index = False)\n",
    "\n",
    "sub_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 10142339,
     "datasetId": 5992922,
     "sourceId": 9887450,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10183589,
     "datasetId": 6026528,
     "sourceId": 9924336,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10129195,
     "datasetId": 6062948,
     "sourceId": 9875624,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10153598,
     "datasetId": 5985683,
     "sourceId": 9897483,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10174033,
     "datasetId": 6086849,
     "sourceId": 9915733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
