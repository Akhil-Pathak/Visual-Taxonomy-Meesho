{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:36.983085Z",
     "iopub.status.busy": "2024-11-16T13:22:36.982706Z",
     "iopub.status.idle": "2024-11-16T13:22:37.866504Z",
     "shell.execute_reply": "2024-11-16T13:22:37.865586Z",
     "shell.execute_reply.started": "2024-11-16T13:22:36.983047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:37.868862Z",
     "iopub.status.busy": "2024-11-16T13:22:37.868440Z",
     "iopub.status.idle": "2024-11-16T13:22:37.872695Z",
     "shell.execute_reply": "2024-11-16T13:22:37.871861Z",
     "shell.execute_reply.started": "2024-11-16T13:22:37.868825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_category = 'Sarees'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:37.873988Z",
     "iopub.status.busy": "2024-11-16T13:22:37.873694Z",
     "iopub.status.idle": "2024-11-16T13:22:37.879626Z",
     "shell.execute_reply": "2024-11-16T13:22:37.878661Z",
     "shell.execute_reply.started": "2024-11-16T13:22:37.873958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_eff_b6 = \"../../Models/eff_net_b6_fillna_eff_net_Sarees.pth\"\n",
    "path_eff_b5 = \"../../Models/eff_net_fillna_eff_net_Sarees.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:37.880956Z",
     "iopub.status.busy": "2024-11-16T13:22:37.880652Z",
     "iopub.status.idle": "2024-11-16T13:22:38.013978Z",
     "shell.execute_reply": "2024-11-16T13:22:38.013154Z",
     "shell.execute_reply.started": "2024-11-16T13:22:37.880917Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7432</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>small border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>applique</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7433</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>traditional</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>elephant</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7434</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>white</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>floral</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7435</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>traditional</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7436</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>solid</td>\n",
       "      <td>no border</td>\n",
       "      <td>small border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>daily</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>yes</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>25773</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>peacock</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>25774</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>no border</td>\n",
       "      <td>no border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>default</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18343</th>\n",
       "      <td>25775</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>peacock</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18344</th>\n",
       "      <td>25776</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>temple border</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>peacock</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18345</th>\n",
       "      <td>25777</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>checked</td>\n",
       "      <td>no</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/train_images/025...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18346 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len         attr_1         attr_2        attr_3  \\\n",
       "0       7432   Sarees   10  same as saree   woven design  small border   \n",
       "1       7433   Sarees   10  same as saree           zari  small border   \n",
       "2       7434   Sarees   10  same as saree           zari  small border   \n",
       "3       7435   Sarees   10  same as saree   woven design    big border   \n",
       "4       7436   Sarees   10          solid      no border  small border   \n",
       "...      ...      ...  ...            ...            ...           ...   \n",
       "18341  25773   Sarees   10  same as saree           zari  small border   \n",
       "18342  25774   Sarees   10  same as saree      no border     no border   \n",
       "18343  25775   Sarees   10  same as saree           zari  small border   \n",
       "18344  25776   Sarees   10  same as saree  temple border  small border   \n",
       "18345  25777   Sarees   10  same as saree   woven design    big border   \n",
       "\n",
       "           attr_4       attr_5    attr_6         attr_7      attr_8  \\\n",
       "0      multicolor        party  jacquard   woven design  zari woven   \n",
       "1           cream  traditional  jacquard   woven design  zari woven   \n",
       "2           white        party  jacquard   woven design  zari woven   \n",
       "3         default  traditional  jacquard  same as saree  zari woven   \n",
       "4      multicolor        daily   default  same as saree     printed   \n",
       "...           ...          ...       ...            ...         ...   \n",
       "18341       cream        party  jacquard   woven design  zari woven   \n",
       "18342     default        party   default     zari woven  zari woven   \n",
       "18343       cream        party  jacquard   woven design  zari woven   \n",
       "18344       cream        party  jacquard   woven design  zari woven   \n",
       "18345  multicolor        party  jacquard   woven design  zari woven   \n",
       "\n",
       "             attr_9 attr_10                                         image_path  \n",
       "0          applique      no  /kaggle/input/visual-taxonomy/train_images/007...  \n",
       "1          elephant      no  /kaggle/input/visual-taxonomy/train_images/007...  \n",
       "2            floral      no  /kaggle/input/visual-taxonomy/train_images/007...  \n",
       "3      ethnic motif      no  /kaggle/input/visual-taxonomy/train_images/007...  \n",
       "4           default     yes  /kaggle/input/visual-taxonomy/train_images/007...  \n",
       "...             ...     ...                                                ...  \n",
       "18341       peacock      no  /kaggle/input/visual-taxonomy/train_images/025...  \n",
       "18342       default      no  /kaggle/input/visual-taxonomy/train_images/025...  \n",
       "18343       peacock      no  /kaggle/input/visual-taxonomy/train_images/025...  \n",
       "18344       peacock      no  /kaggle/input/visual-taxonomy/train_images/025...  \n",
       "18345       checked      no  /kaggle/input/visual-taxonomy/train_images/025...  \n",
       "\n",
       "[18346 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_Men_Tshirts = pd.read_csv('../../Preprocessor-FillNA/output/train_fillna_sarees_effnet_b5_4epochs.csv')\n",
    "train_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:38.016605Z",
     "iopub.status.busy": "2024-11-16T13:22:38.016310Z",
     "iopub.status.idle": "2024-11-16T13:22:38.025379Z",
     "shell.execute_reply": "2024-11-16T13:22:38.024500Z",
     "shell.execute_reply.started": "2024-11-16T13:22:38.016574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attr_1', 'attr_2', 'attr_3', 'attr_4', 'attr_5', 'attr_6', 'attr_7', 'attr_8', 'attr_9', 'attr_10']\n"
     ]
    }
   ],
   "source": [
    "attr_columns = train_df_Men_Tshirts.filter(like='attr_').columns.to_list() # Adjust if more attributes exist\n",
    "print(attr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:38.026844Z",
     "iopub.status.busy": "2024-11-16T13:22:38.026468Z",
     "iopub.status.idle": "2024-11-16T13:22:39.032088Z",
     "shell.execute_reply": "2024-11-16T13:22:39.031121Z",
     "shell.execute_reply.started": "2024-11-16T13:22:38.026785Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder for each attribute column\n",
    "label_encoders = {}\n",
    "for column in attr_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_df_Men_Tshirts[column] = le.fit_transform(train_df_Men_Tshirts[column])\n",
    "    label_encoders[column] = le  # Store the encoder for inverse transformation later if needed\n",
    "\n",
    "# Check the updated DataFrame\n",
    "# train_df_Men_Tshirts = train_df_Men_Tshirts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:39.033541Z",
     "iopub.status.busy": "2024-11-16T13:22:39.033135Z",
     "iopub.status.idle": "2024-11-16T13:22:39.107607Z",
     "shell.execute_reply": "2024-11-16T13:22:39.106841Z",
     "shell.execute_reply.started": "2024-11-16T13:22:39.033508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df1, val_df1 = train_test_split(train_df_Men_Tshirts, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:39.109108Z",
     "iopub.status.busy": "2024-11-16T13:22:39.108744Z",
     "iopub.status.idle": "2024-11-16T13:22:43.340162Z",
     "shell.execute_reply": "2024-11-16T13:22:43.339314Z",
     "shell.execute_reply.started": "2024-11-16T13:22:39.109069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test  # Flag to indicate if it's test set without labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_dir + self.dataframe.iloc[idx]['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:  # For test set, just return the image without labels\n",
    "            return image\n",
    "        \n",
    "        # For train/validation set, return image and labels\n",
    "        labels = self.dataframe.iloc[idx][attr_columns].values\n",
    "        labels = labels.astype(np.int64)  # Ensure labels are integers\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return image, labels\n",
    "    \n",
    "    \n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Apply Color Jitter\n",
    "    transforms.RandomHorizontalFlip(),  # Apply Horizontal Flip with 50% probability\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "    \n",
    "train_dataset = CustomDataset(dataframe=train_df1, img_dir='', transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=val_df1, img_dir='', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:43.341933Z",
     "iopub.status.busy": "2024-11-16T13:22:43.341440Z",
     "iopub.status.idle": "2024-11-16T13:22:43.346043Z",
     "shell.execute_reply": "2024-11-16T13:22:43.345141Z",
     "shell.execute_reply.started": "2024-11-16T13:22:43.341898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:43.347491Z",
     "iopub.status.busy": "2024-11-16T13:22:43.347171Z",
     "iopub.status.idle": "2024-11-16T13:22:45.577072Z",
     "shell.execute_reply": "2024-11-16T13:22:45.576056Z",
     "shell.execute_reply.started": "2024-11-16T13:22:43.347454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B6_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B6_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b6_lukemelas-24a108a5.pth\n",
      "100%|██████████| 165M/165M [00:00<00:00, 183MB/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "class MultiOutputModel1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiOutputModel1, self).__init__()\n",
    "        # Use MobileNetV2 as the base model\n",
    "        self.base_model = models.efficientnet_b6(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()  # Remove original classification layer\n",
    "        \n",
    "        # Add an adaptive pooling layer to make sure output is flat\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))  # Convert 2D output to 1D\n",
    "        \n",
    "        # Dynamically create a fully connected layer for each attribute\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        for attr, n_classes in num_classes.items():\n",
    "            self.output_layers[attr] = nn.Linear(2304, n_classes)  # Adjust input to 1280 for MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)  # Extract features\n",
    "        x = self.pooling(x)  # Adaptive pool to (1, 1) shape\n",
    "        x = torch.flatten(x, 1)  # Flatten the output to (batch_size, 1280)\n",
    "        \n",
    "        outputs = {}\n",
    "        # Dynamically compute output for each attribute\n",
    "        for attr, layer in self.output_layers.items():\n",
    "            outputs[attr] = layer(x)\n",
    "        \n",
    "        return list(outputs.values())\n",
    "\n",
    "# Example usage\n",
    "num_classes = {}\n",
    "for key in attr_columns:\n",
    "    num_classes[key] = train_df_Men_Tshirts[key].nunique()\n",
    "\n",
    "model_eff_b6 = MultiOutputModel1(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff_b6.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:45.578936Z",
     "iopub.status.busy": "2024-11-16T13:22:45.578578Z",
     "iopub.status.idle": "2024-11-16T13:22:46.961099Z",
     "shell.execute_reply": "2024-11-16T13:22:46.960127Z",
     "shell.execute_reply.started": "2024-11-16T13:22:45.578902Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b5_lukemelas-1a07897c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b5_lukemelas-1a07897c.pth\n",
      "100%|██████████| 117M/117M [00:00<00:00, 202MB/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "class MultiOutputModel2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiOutputModel2, self).__init__()\n",
    "        # Use MobileNetV2 as the base model\n",
    "        self.base_model = models.efficientnet_b5(pretrained=True)\n",
    "        self.base_model.classifier = nn.Identity()  # Remove original classification layer\n",
    "        \n",
    "        # Add an adaptive pooling layer to make sure output is flat\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))  # Convert 2D output to 1D\n",
    "        \n",
    "        # Dynamically create a fully connected layer for each attribute\n",
    "        self.output_layers = nn.ModuleDict()\n",
    "        for attr, n_classes in num_classes.items():\n",
    "            self.output_layers[attr] = nn.Linear(2048, n_classes)  # Adjust input to 1280 for MobileNetV2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)  # Extract features\n",
    "        x = self.pooling(x)  # Adaptive pool to (1, 1) shape\n",
    "        x = torch.flatten(x, 1)  # Flatten the output to (batch_size, 1280)\n",
    "        \n",
    "        outputs = {}\n",
    "        # Dynamically compute output for each attribute\n",
    "        for attr, layer in self.output_layers.items():\n",
    "            outputs[attr] = layer(x)\n",
    "        \n",
    "        return list(outputs.values())\n",
    "\n",
    "# Example usage\n",
    "num_classes = {}\n",
    "for key in attr_columns:\n",
    "    num_classes[key] = train_df_Men_Tshirts[key].nunique()\n",
    "\n",
    "model_eff_b5 = MultiOutputModel2(num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_eff_b5.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:46.962720Z",
     "iopub.status.busy": "2024-11-16T13:22:46.962402Z",
     "iopub.status.idle": "2024-11-16T13:22:47.342360Z",
     "shell.execute_reply": "2024-11-16T13:22:47.341362Z",
     "shell.execute_reply.started": "2024-11-16T13:22:46.962687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_eff_b6 = model_eff_b6.to(device)\n",
    "model_eff_b5 =  model_eff_b5.to(device)\n",
    "# Training loop\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, save_path=f\"eff_net_b6_fillna_eff_net_{model_category}.pth\"):\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer = optimizer , step_size=5, gamma=0.5)\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move tensors to the correct device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = sum([criterion(output, label) for output, label in zip(outputs, labels.T)])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader)}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)  # Move tensors to the correct device\n",
    "                outputs = model(images)\n",
    "                loss = sum([criterion(output, label) for output, label in zip(outputs, labels.T)])\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'Epoch {epoch+1}, Val Loss: {val_loss/len(val_loader)}')\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved with Val Loss: {best_val_loss:.4f} at Epoch {epoch+1}\")\n",
    "\n",
    "# Run training\n",
    "# train(model, train_loader, val_loader, criterion, optimizer, num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:47.343983Z",
     "iopub.status.busy": "2024-11-16T13:22:47.343581Z",
     "iopub.status.idle": "2024-11-16T13:22:49.443361Z",
     "shell.execute_reply": "2024-11-16T13:22:49.442349Z",
     "shell.execute_reply.started": "2024-11-16T13:22:47.343937Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/563325272.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_eff_b6.load_state_dict(torch.load(f\"{path_eff_b6}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_eff_b6.load_state_dict(torch.load(f\"{path_eff_b6}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:49.448697Z",
     "iopub.status.busy": "2024-11-16T13:22:49.447784Z",
     "iopub.status.idle": "2024-11-16T13:22:50.340641Z",
     "shell.execute_reply": "2024-11-16T13:22:50.339731Z",
     "shell.execute_reply.started": "2024-11-16T13:22:49.448655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/399784212.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_eff_b5.load_state_dict(torch.load(f\"{path_eff_b5}\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_eff_b5.load_state_dict(torch.load(f\"{path_eff_b5}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.341915Z",
     "iopub.status.busy": "2024-11-16T13:22:50.341608Z",
     "iopub.status.idle": "2024-11-16T13:22:50.368470Z",
     "shell.execute_reply": "2024-11-16T13:22:50.367624Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.341883Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputModel1(\n",
       "  (base_model): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(56, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n",
       "              (1): BatchNorm2d(56, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(56, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(14, 56, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(56, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0044444444444444444, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.008888888888888889, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.013333333333333336, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.017777777777777778, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.022222222222222223, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.026666666666666672, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.031111111111111114, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.035555555555555556, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.044444444444444446, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04888888888888889, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.053333333333333344, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05777777777777778, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06222222222222223, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 432, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 432, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=432, bias=False)\n",
       "              (1): BatchNorm2d(432, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(432, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(18, 432, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(432, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07111111111111111, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07555555555555557, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08444444444444445, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08888888888888889, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09777777777777778, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 864, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=864, bias=False)\n",
       "              (1): BatchNorm2d(864, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(864, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(36, 864, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(864, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10222222222222223, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10666666666666669, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1111111111111111, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11555555555555556, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12444444444444445, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12888888888888891, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 1200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 1200, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1200, bias=False)\n",
       "              (1): BatchNorm2d(1200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1200, 50, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(50, 1200, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1200, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13777777777777778, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14222222222222222, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15111111111111114, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15555555555555556, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16444444444444445, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1688888888888889, mode=row)\n",
       "        )\n",
       "        (8): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
       "        )\n",
       "        (9): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17777777777777778, mode=row)\n",
       "        )\n",
       "        (10): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 344, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(344, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18222222222222226, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(344, 2064, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 2064, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2064, bias=False)\n",
       "              (1): BatchNorm2d(2064, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(2064, 86, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(86, 2064, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(2064, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 3456, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3456, bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3456, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(144, 3456, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1911111111111111, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(576, 3456, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 3456, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3456, bias=False)\n",
       "              (1): BatchNorm2d(3456, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3456, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(144, 3456, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3456, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19555555555555557, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layers): ModuleDict(\n",
       "    (attr_1): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_2): Linear(in_features=2304, out_features=6, bias=True)\n",
       "    (attr_3): Linear(in_features=2304, out_features=3, bias=True)\n",
       "    (attr_4): Linear(in_features=2304, out_features=8, bias=True)\n",
       "    (attr_5): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_6): Linear(in_features=2304, out_features=3, bias=True)\n",
       "    (attr_7): Linear(in_features=2304, out_features=4, bias=True)\n",
       "    (attr_8): Linear(in_features=2304, out_features=5, bias=True)\n",
       "    (attr_9): Linear(in_features=2304, out_features=9, bias=True)\n",
       "    (attr_10): Linear(in_features=2304, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_eff_b6.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.369872Z",
     "iopub.status.busy": "2024-11-16T13:22:50.369558Z",
     "iopub.status.idle": "2024-11-16T13:22:50.392956Z",
     "shell.execute_reply": "2024-11-16T13:22:50.392072Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.369841Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputModel2(\n",
       "  (base_model): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "              (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.005128205128205128, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.010256410256410256, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.015384615384615387, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.020512820512820513, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.02564102564102564, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.030769230769230774, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0358974358974359, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.041025641025641026, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.046153846153846156, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05128205128205128, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05641025641025642, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06153846153846155, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0717948717948718, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08205128205128205, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08717948717948719, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09230769230769231, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09743589743589744, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10256410256410256, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11282051282051284, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11794871794871796, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1230769230769231, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1282051282051282, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(176, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1056, bias=False)\n",
       "              (1): BatchNorm2d(1056, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1435897435897436, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14871794871794874, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.158974358974359, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1641025641025641, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17435897435897438, mode=row)\n",
       "        )\n",
       "        (8): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(304, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1794871794871795, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
       "              (1): BatchNorm2d(1824, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18461538461538463, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18974358974358976, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
       "              (1): BatchNorm2d(3072, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19487179487179487, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layers): ModuleDict(\n",
       "    (attr_1): Linear(in_features=2048, out_features=4, bias=True)\n",
       "    (attr_2): Linear(in_features=2048, out_features=6, bias=True)\n",
       "    (attr_3): Linear(in_features=2048, out_features=3, bias=True)\n",
       "    (attr_4): Linear(in_features=2048, out_features=8, bias=True)\n",
       "    (attr_5): Linear(in_features=2048, out_features=4, bias=True)\n",
       "    (attr_6): Linear(in_features=2048, out_features=3, bias=True)\n",
       "    (attr_7): Linear(in_features=2048, out_features=4, bias=True)\n",
       "    (attr_8): Linear(in_features=2048, out_features=5, bias=True)\n",
       "    (attr_9): Linear(in_features=2048, out_features=9, bias=True)\n",
       "    (attr_10): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_eff_b5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.394470Z",
     "iopub.status.busy": "2024-11-16T13:22:50.394132Z",
     "iopub.status.idle": "2024-11-16T13:22:50.422543Z",
     "shell.execute_reply": "2024-11-16T13:22:50.421602Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.394430Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men Tshirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>30484</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>30485</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30202</th>\n",
       "      <td>30486</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30203</th>\n",
       "      <td>30487</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30204</th>\n",
       "      <td>30488</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category\n",
       "0          0          Men Tshirts\n",
       "1          1          Men Tshirts\n",
       "2          2          Men Tshirts\n",
       "3          3          Men Tshirts\n",
       "4          4          Men Tshirts\n",
       "...      ...                  ...\n",
       "30200  30484  Women Tops & Tunics\n",
       "30201  30485  Women Tops & Tunics\n",
       "30202  30486  Women Tops & Tunics\n",
       "30203  30487  Women Tops & Tunics\n",
       "30204  30488  Women Tops & Tunics\n",
       "\n",
       "[30205 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../Dataset/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.424560Z",
     "iopub.status.busy": "2024-11-16T13:22:50.423784Z",
     "iopub.status.idle": "2024-11-16T13:22:50.523355Z",
     "shell.execute_reply": "2024-11-16T13:22:50.522464Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.424514Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/2828864867.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts['len'] = 10\n",
      "/tmp/ipykernel_30/2828864867.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts['image_path'] = test_df_Men_Tshirts.apply(format_image_path_test, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>3788</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>3789</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3790</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>3791</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>11150</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>11151</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>11152</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>11153</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>11154</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len                                         image_path\n",
       "3787    3787   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...\n",
       "3788    3788   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...\n",
       "3789    3789   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...\n",
       "3790    3790   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...\n",
       "3791    3791   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...\n",
       "...      ...      ...  ...                                                ...\n",
       "10884  11150   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...\n",
       "10885  11151   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...\n",
       "10886  11152   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...\n",
       "10887  11153   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...\n",
       "10888  11154   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...\n",
       "\n",
       "[7102 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_Men_Tshirts = test_df[test_df['Category'] == model_category]\n",
    "test_df_Men_Tshirts['len'] = 10\n",
    "\n",
    "def format_image_path_test(row):\n",
    "    return f\"../../Dataset/test_images/{str(row['id']).zfill(6)}.jpg\"\n",
    "\n",
    "test_df_Men_Tshirts['image_path'] = test_df_Men_Tshirts.apply(format_image_path_test, axis=1)\n",
    "test_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.530443Z",
     "iopub.status.busy": "2024-11-16T13:22:50.530126Z",
     "iopub.status.idle": "2024-11-16T13:22:50.535983Z",
     "shell.execute_reply": "2024-11-16T13:22:50.535059Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.530395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test dataset without labels\n",
    "test_dataset = CustomDataset(dataframe=test_df_Men_Tshirts, img_dir='', transform=transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.537418Z",
     "iopub.status.busy": "2024-11-16T13:22:50.537095Z",
     "iopub.status.idle": "2024-11-16T13:22:50.546155Z",
     "shell.execute_reply": "2024-11-16T13:22:50.545112Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.537385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:22:50.547757Z",
     "iopub.status.busy": "2024-11-16T13:22:50.547412Z",
     "iopub.status.idle": "2024-11-16T13:26:23.951264Z",
     "shell.execute_reply": "2024-11-16T13:26:23.950287Z",
     "shell.execute_reply.started": "2024-11-16T13:22:50.547718Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:33<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2 ... 0 3 0]\n",
      " [1 4 0 ... 4 5 0]\n",
      " [3 5 0 ... 2 8 0]\n",
      " ...\n",
      " [2 4 0 ... 4 3 0]\n",
      " [2 4 0 ... 4 3 0]\n",
      " [2 5 2 ... 4 7 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Use console version of tqdm\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader):  # This will display in the console\n",
    "        images = images.cuda() if torch.cuda.is_available() else images\n",
    "\n",
    "        # Forward pass through both models\n",
    "        torch.manual_seed(42)\n",
    "        outputs1 = model_eff_b6(images)\n",
    "        outputs2 = model_eff_b5(images)\n",
    "\n",
    "        # Initialize a list to hold blended predictions for the batch\n",
    "        batch_preds = []\n",
    "\n",
    "        # Loop through the outputs and blend predictions for each attribute\n",
    "        for out1, out2 in zip(outputs1, outputs2):\n",
    "            # Blend logits by averaging\n",
    "            blended_output = (out1 + out2)/2\n",
    "\n",
    "            # Get the predicted classes from the blended output\n",
    "            _, pred = torch.max(blended_output, 1)\n",
    "            batch_preds.append(pred.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "\n",
    "        # Stack predictions along a new dimension and add to predictions list\n",
    "        predictions.append(np.stack(batch_preds, axis=1))  # Shape: (batch_size, num_attributes)\n",
    "\n",
    "# Combine all predictions into a single array\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Display final predictions\n",
    "print(predictions)  # This will be an array with shape (num_samples, num_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:23.953090Z",
     "iopub.status.busy": "2024-11-16T13:26:23.952710Z",
     "iopub.status.idle": "2024-11-16T13:26:23.975499Z",
     "shell.execute_reply": "2024-11-16T13:26:23.974525Z",
     "shell.execute_reply.started": "2024-11-16T13:26:23.953049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[f'attr_{i}'] = np.nan\n",
      "/tmp/ipykernel_30/1201814413.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr_columns] = predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>3788</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>3789</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3790</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>3791</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Category  len                                         image_path  \\\n",
       "3787  3787   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3788  3788   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3789  3789   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3790  3790   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3791  3791   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "\n",
       "      attr_1  attr_2  attr_3  attr_4  attr_5  attr_6  attr_7  attr_8  attr_9  \\\n",
       "3787       0       0       2       1       1       0       1       0       3   \n",
       "3788       1       4       0       3       0       1       3       4       5   \n",
       "3789       3       5       0       1       1       1       3       2       8   \n",
       "3790       1       4       0       1       2       1       3       4       5   \n",
       "3791       0       4       1       3       2       0       3       4       3   \n",
       "\n",
       "      attr_10  \n",
       "3787        0  \n",
       "3788        0  \n",
       "3789        0  \n",
       "3790        0  \n",
       "3791        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming predictions is a numpy array of shape (N, 5)\n",
    "# Add new columns attr_1 to attr_10 to test_df\n",
    "for i in range(1, 11):\n",
    "    test_df_Men_Tshirts[f'attr_{i}'] = np.nan \n",
    "\n",
    "# Assign predictions to attr_1 to attr_5\n",
    "test_df_Men_Tshirts[attr_columns] = predictions\n",
    "\n",
    "# Optionally save the updated test_df to CSV\n",
    "# test_df.to_csv('test_predictions_with_attrs.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "test_df_Men_Tshirts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:23.977537Z",
     "iopub.status.busy": "2024-11-16T13:26:23.976808Z",
     "iopub.status.idle": "2024-11-16T13:26:24.011273Z",
     "shell.execute_reply": "2024-11-16T13:26:24.010411Z",
     "shell.execute_reply.started": "2024-11-16T13:26:23.977477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
      "/tmp/ipykernel_30/688606145.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>image_path</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>small border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>3788</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>same as border</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>daily</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>3789</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>solid</td>\n",
       "      <td>zari</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3790</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>same as border</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>traditional</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>3791</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0037...</td>\n",
       "      <td>default</td>\n",
       "      <td>woven design</td>\n",
       "      <td>no border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>11150</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "      <td>default</td>\n",
       "      <td>woven design</td>\n",
       "      <td>no border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>11151</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "      <td>same as border</td>\n",
       "      <td>zari</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>11152</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>daily</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>11153</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>11154</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>/kaggle/input/visual-taxonomy/test_images/0111...</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>peacock</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len                                         image_path  \\\n",
       "3787    3787   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3788    3788   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3789    3789   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3790    3790   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "3791    3791   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0037...   \n",
       "...      ...      ...  ...                                                ...   \n",
       "10884  11150   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...   \n",
       "10885  11151   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...   \n",
       "10886  11152   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...   \n",
       "10887  11153   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...   \n",
       "10888  11154   Sarees   10  /kaggle/input/visual-taxonomy/test_images/0111...   \n",
       "\n",
       "               attr_1        attr_2        attr_3      attr_4       attr_5  \\\n",
       "3787          default       default  small border     default        party   \n",
       "3788   same as border  woven design    big border  multicolor        daily   \n",
       "3789            solid          zari    big border     default        party   \n",
       "3790   same as border  woven design    big border     default  traditional   \n",
       "3791          default  woven design     no border  multicolor  traditional   \n",
       "...               ...           ...           ...         ...          ...   \n",
       "10884         default  woven design     no border  multicolor  traditional   \n",
       "10885  same as border          zari    big border     default        party   \n",
       "10886   same as saree  woven design    big border     default        daily   \n",
       "10887   same as saree  woven design    big border     default  traditional   \n",
       "10888   same as saree          zari  small border       cream        party   \n",
       "\n",
       "         attr_6         attr_7      attr_8        attr_9 attr_10  \n",
       "3787    default  same as saree     default       default      no  \n",
       "3788   jacquard     zari woven  zari woven  ethnic motif      no  \n",
       "3789   jacquard     zari woven       solid         solid      no  \n",
       "3790   jacquard     zari woven  zari woven  ethnic motif      no  \n",
       "3791    default     zari woven  zari woven       default      no  \n",
       "...         ...            ...         ...           ...     ...  \n",
       "10884   default     zari woven  zari woven       default      no  \n",
       "10885   default  same as saree  zari woven       default      no  \n",
       "10886  jacquard     zari woven  zari woven       default      no  \n",
       "10887   default  same as saree  zari woven       default      no  \n",
       "10888  jacquard   woven design  zari woven       peacock      no  \n",
       "\n",
       "[7102 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse transform predictions for each attribute using the stored label encoders\n",
    "for attr in attr_columns:\n",
    "    # Inverse transform using the corresponding label encoder\n",
    "    test_df_Men_Tshirts[attr] = label_encoders[attr].inverse_transform(test_df_Men_Tshirts[attr].astype(int))\n",
    "\n",
    "# Check the updated DataFrame¯ with original attribute names instead of encoded numbers\n",
    "test_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:24.012701Z",
     "iopub.status.busy": "2024-11-16T13:26:24.012348Z",
     "iopub.status.idle": "2024-11-16T13:26:24.031876Z",
     "shell.execute_reply": "2024-11-16T13:26:24.030753Z",
     "shell.execute_reply.started": "2024-11-16T13:26:24.012658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for attr_1:\n",
      "\n",
      "attr_1\n",
      "same as saree     4131\n",
      "same as border    1469\n",
      "default           1063\n",
      "solid              439\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_2:\n",
      "\n",
      "attr_2\n",
      "woven design     2502\n",
      "zari             2384\n",
      "default          1406\n",
      "temple border     465\n",
      "solid             201\n",
      "no border         144\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_3:\n",
      "\n",
      "attr_3\n",
      "small border    3304\n",
      "big border      3265\n",
      "no border        533\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_4:\n",
      "\n",
      "attr_4\n",
      "default       3189\n",
      "cream         1864\n",
      "multicolor    1478\n",
      "navy blue      134\n",
      "yellow         122\n",
      "pink           122\n",
      "white          115\n",
      "green           78\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_5:\n",
      "\n",
      "attr_5\n",
      "party          4406\n",
      "traditional    1598\n",
      "wedding         564\n",
      "daily           534\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_6:\n",
      "\n",
      "attr_6\n",
      "jacquard               3972\n",
      "default                2435\n",
      "tassels and latkans     695\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_7:\n",
      "\n",
      "attr_7\n",
      "same as saree    2891\n",
      "woven design     2404\n",
      "zari woven       1619\n",
      "default           188\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_8:\n",
      "\n",
      "attr_8\n",
      "zari woven      5008\n",
      "default         1185\n",
      "solid            585\n",
      "woven design     210\n",
      "printed          114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_9:\n",
      "\n",
      "attr_9\n",
      "default         2700\n",
      "floral          1154\n",
      "ethnic motif    1148\n",
      "peacock          785\n",
      "solid            598\n",
      "checked          357\n",
      "elephant         307\n",
      "botanical         51\n",
      "applique           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Value counts for attr_10:\n",
      "\n",
      "attr_10\n",
      "no     6794\n",
      "yes     308\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get value counts for each specified column\n",
    "columns_of_interest = attr_columns\n",
    "\n",
    "for column in columns_of_interest:\n",
    "    print(f\"Value counts for {column}:\\n\")\n",
    "    print(test_df_Men_Tshirts[column].value_counts(dropna=False))  # Including NaN values\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:24.033315Z",
     "iopub.status.busy": "2024-11-16T13:26:24.033005Z",
     "iopub.status.idle": "2024-11-16T13:26:24.056638Z",
     "shell.execute_reply": "2024-11-16T13:26:24.055770Z",
     "shell.execute_reply.started": "2024-11-16T13:26:24.033271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47001</td>\n",
       "      <td>Women Tshirts</td>\n",
       "      <td>8</td>\n",
       "      <td>maroon</td>\n",
       "      <td>regular</td>\n",
       "      <td>crop</td>\n",
       "      <td>printed</td>\n",
       "      <td>typography</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>default</td>\n",
       "      <td>nu</td>\n",
       "      <td>nu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16431</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree\\n</td>\n",
       "      <td>temple border</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55700</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>white</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>round neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>knitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15698</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree\\n</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>white</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design\\n</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>floral</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30330</td>\n",
       "      <td>Kurtis</td>\n",
       "      <td>9</td>\n",
       "      <td>yellow</td>\n",
       "      <td>a-line</td>\n",
       "      <td>knee length\\n</td>\n",
       "      <td>daily</td>\n",
       "      <td>net</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>three-quarter sleeves</td>\n",
       "      <td>regular</td>\n",
       "      <td>nu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             Category  len           attr_1         attr_2  \\\n",
       "0  47001        Women Tshirts    8           maroon        regular   \n",
       "1  16431               Sarees   10  same as saree\\n  temple border   \n",
       "2  55700  Women Tops & Tunics   10            white         fitted   \n",
       "3  15698               Sarees   10  same as saree\\n           zari   \n",
       "4  30330               Kurtis    9           yellow         a-line   \n",
       "\n",
       "          attr_3      attr_4      attr_5         attr_6           attr_7  \\\n",
       "0           crop     printed  typography  short sleeves  regular sleeves   \n",
       "1   small border       cream       party       jacquard     woven design   \n",
       "2        regular  round neck      casual          solid            solid   \n",
       "3   small border       white       party       jacquard   woven design\\n   \n",
       "4  knee length\\n       daily         net        default            solid   \n",
       "\n",
       "                  attr_8           attr_9  attr_10  \n",
       "0                default               nu       nu  \n",
       "1             zari woven     ethnic motif       no  \n",
       "2          short sleeves  regular sleeves  knitted  \n",
       "3             zari woven           floral       no  \n",
       "4  three-quarter sleeves          regular       nu  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.read_csv('../../Dataset/sample_submission.csv')\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:24.058631Z",
     "iopub.status.busy": "2024-11-16T13:26:24.057946Z",
     "iopub.status.idle": "2024-11-16T13:26:24.074851Z",
     "shell.execute_reply": "2024-11-16T13:26:24.074070Z",
     "shell.execute_reply.started": "2024-11-16T13:26:24.058583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df_Men_Tshirts = test_df_Men_Tshirts.fillna('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T13:26:24.076372Z",
     "iopub.status.busy": "2024-11-16T13:26:24.076070Z",
     "iopub.status.idle": "2024-11-16T13:26:24.153854Z",
     "shell.execute_reply": "2024-11-16T13:26:24.152977Z",
     "shell.execute_reply.started": "2024-11-16T13:26:24.076340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>small border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>default</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>3788</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as border</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>daily</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>3789</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>solid</td>\n",
       "      <td>zari</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3790</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as border</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>traditional</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>ethnic motif</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>3791</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>woven design</td>\n",
       "      <td>no border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>11150</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>woven design</td>\n",
       "      <td>no border</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10885</th>\n",
       "      <td>11151</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as border</td>\n",
       "      <td>zari</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>party</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10886</th>\n",
       "      <td>11152</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>daily</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10887</th>\n",
       "      <td>11153</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>woven design</td>\n",
       "      <td>big border</td>\n",
       "      <td>default</td>\n",
       "      <td>traditional</td>\n",
       "      <td>default</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>default</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10888</th>\n",
       "      <td>11154</td>\n",
       "      <td>Sarees</td>\n",
       "      <td>10</td>\n",
       "      <td>same as saree</td>\n",
       "      <td>zari</td>\n",
       "      <td>small border</td>\n",
       "      <td>cream</td>\n",
       "      <td>party</td>\n",
       "      <td>jacquard</td>\n",
       "      <td>woven design</td>\n",
       "      <td>zari woven</td>\n",
       "      <td>peacock</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id Category  len          attr_1        attr_2        attr_3  \\\n",
       "3787    3787   Sarees   10         default       default  small border   \n",
       "3788    3788   Sarees   10  same as border  woven design    big border   \n",
       "3789    3789   Sarees   10           solid          zari    big border   \n",
       "3790    3790   Sarees   10  same as border  woven design    big border   \n",
       "3791    3791   Sarees   10         default  woven design     no border   \n",
       "...      ...      ...  ...             ...           ...           ...   \n",
       "10884  11150   Sarees   10         default  woven design     no border   \n",
       "10885  11151   Sarees   10  same as border          zari    big border   \n",
       "10886  11152   Sarees   10   same as saree  woven design    big border   \n",
       "10887  11153   Sarees   10   same as saree  woven design    big border   \n",
       "10888  11154   Sarees   10   same as saree          zari  small border   \n",
       "\n",
       "           attr_4       attr_5    attr_6         attr_7      attr_8  \\\n",
       "3787      default        party   default  same as saree     default   \n",
       "3788   multicolor        daily  jacquard     zari woven  zari woven   \n",
       "3789      default        party  jacquard     zari woven       solid   \n",
       "3790      default  traditional  jacquard     zari woven  zari woven   \n",
       "3791   multicolor  traditional   default     zari woven  zari woven   \n",
       "...           ...          ...       ...            ...         ...   \n",
       "10884  multicolor  traditional   default     zari woven  zari woven   \n",
       "10885     default        party   default  same as saree  zari woven   \n",
       "10886     default        daily  jacquard     zari woven  zari woven   \n",
       "10887     default  traditional   default  same as saree  zari woven   \n",
       "10888       cream        party  jacquard   woven design  zari woven   \n",
       "\n",
       "             attr_9 attr_10  \n",
       "3787        default      no  \n",
       "3788   ethnic motif      no  \n",
       "3789          solid      no  \n",
       "3790   ethnic motif      no  \n",
       "3791        default      no  \n",
       "...             ...     ...  \n",
       "10884       default      no  \n",
       "10885       default      no  \n",
       "10886       default      no  \n",
       "10887       default      no  \n",
       "10888       peacock      no  \n",
       "\n",
       "[7102 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df_Men_Tshirts = test_df_Men_Tshirts.drop('image_path', axis = 1)\n",
    "sub_df_Men_Tshirts.to_csv(f\"output/sub_df_{model_category}_effnet_0.5_b6_0.5_b5_blending.csv\", index = False)\n",
    "sub_df_Men_Tshirts.to_csv(f\"sub_df_{model_category}_effnet_0.5_b6_0.5_b5_blending.csv\", index = False)\n",
    "sub_df_Men_Tshirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    },
    {
     "datasetId": 6062948,
     "sourceId": 9875624,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5992922,
     "sourceId": 9887450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5985683,
     "sourceId": 9897483,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6086108,
     "sourceId": 9906223,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6026528,
     "sourceId": 9923890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
